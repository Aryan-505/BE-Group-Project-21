{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 2734496,
          "sourceType": "datasetVersion",
          "datasetId": 1654566
        }
      ],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Rake"
      ],
      "metadata": {
        "id": "ADu1MTL_KCsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rake-nltk gensim stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZ1Y9wgrG6YI",
        "outputId": "da9142c3-1c2c-4fd2-ace2-a9087b2a4bdd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rake-nltk in /usr/local/lib/python3.11/dist-packages (1.0.6)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: stopwords in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from rake-nltk) (3.9.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (4.67.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJqJe0mJH1MB",
        "outputId": "3ea47120-9ed8-458b-c7ed-a97d6e57545f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "from rake_nltk import Rake\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "# Initializing the Rake instance\n",
        "rake = Rake()\n",
        "\n",
        "# Input text\n",
        "input_text = '''\n",
        "NLP stands for Natural Language Processing.\n",
        "It is the branch of Artificial Intelligence that gives the ability to machine understand\n",
        "and process human languages. Human languages can be in the form of text or audio format.\n",
        "Natural Language Processing started in 1950 When Alan Mathison Turing published\n",
        "an article in the name Computing Machinery and Intelligence.\n",
        "It is based on Artificial intelligence. It talks about automatic interpretation and\n",
        "generation of natural language.\n",
        "As the technology evolved, different approaches have come to deal with NLP tasks.\n",
        "'''\n",
        "\n",
        "# Extracting keywords and phrases\n",
        "rake.extract_keywords_from_text(input_text)\n",
        "keywords = rake.get_ranked_phrases_with_scores()\n",
        "\n",
        "df = pd.DataFrame(keywords, columns=['Score', 'Keyword'])\n",
        "\n",
        "# Displaying the table\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqJ08RdHDott",
        "outputId": "8552f05d-7352-42e5-9935-7d773fabc8ef"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Score                              Keyword\n",
            "0   16.000000       alan mathison turing published\n",
            "1   13.500000  natural language processing started\n",
            "2    9.500000          natural language processing\n",
            "3    9.000000             name computing machinery\n",
            "4    8.000000              process human languages\n",
            "5    6.000000                     natural language\n",
            "6    5.000000                      human languages\n",
            "7    4.000000                   technology evolved\n",
            "8    4.000000                            nlp tasks\n",
            "9    4.000000                           nlp stands\n",
            "10   4.000000                   machine understand\n",
            "11   4.000000                 different approaches\n",
            "12   4.000000             automatic interpretation\n",
            "13   4.000000                         audio format\n",
            "14   3.666667              artificial intelligence\n",
            "15   3.666667              artificial intelligence\n",
            "16   1.666667                         intelligence\n",
            "17   1.000000                                 text\n",
            "18   1.000000                                talks\n",
            "19   1.000000                                gives\n",
            "20   1.000000                           generation\n",
            "21   1.000000                                 form\n",
            "22   1.000000                                 deal\n",
            "23   1.000000                                 come\n",
            "24   1.000000                               branch\n",
            "25   1.000000                                based\n",
            "26   1.000000                              article\n",
            "27   1.000000                              ability\n",
            "28   1.000000                                 1950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from rake_nltk import Rake\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "from collections import defaultdict\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Function to extract individual word scores from RAKE phrases\n",
        "def get_rake_word_scores(text):\n",
        "    \"\"\"\n",
        "    Extracts RAKE phrases, splits them into words, assigns each word the phrase score,\n",
        "    and aggregates scores for words appearing in multiple phrases.\n",
        "\n",
        "    Returns: dict {word: aggregated_score}\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return {}\n",
        "\n",
        "    rake = Rake()\n",
        "    rake.extract_keywords_from_text(text)\n",
        "    phrases = rake.get_ranked_phrases_with_scores()  # list of (score, phrase)\n",
        "\n",
        "    word_scores = defaultdict(float)\n",
        "\n",
        "    for score, phrase in phrases:\n",
        "        words = word_tokenize(phrase.lower())\n",
        "        for word in words:\n",
        "            if word.isalnum():  # skip punctuation\n",
        "                word_scores[word] += score  # accumulate score if word appears multiple times\n",
        "    word_scores = {word: round(score, 3) for word, score in word_scores.items()}\n",
        "    return dict(word_scores)\n",
        "\n",
        "# Step 1: Load preprocessed text\n",
        "df = pd.read_csv(\"preprocessed_text.csv\")\n",
        "\n",
        "# Step 2: Apply function to each review\n",
        "df['RAKE_Word_Scores'] = df['Preprocessed_Text'].apply(get_rake_word_scores)\n",
        "\n",
        "# Step 3: Save output\n",
        "df[['Id', 'RAKE_Word_Scores']].to_csv(\"rake_word_scores.csv\", index=False)\n",
        "print(\"✅ RAKE word-level scores saved to rake_word_scores.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaJUBG1GWcYl",
        "outputId": "f35fea0a-c813-487b-b801-cc0e3ada1d02"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ RAKE word-level scores saved to rake_word_scores.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Text Rank"
      ],
      "metadata": {
        "id": "lJUKgedgKIE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec\n",
        "from scipy import spatial\n",
        "import networkx as nx"
      ],
      "metadata": {
        "id": "xlUN3TE-Jnmb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from itertools import combinations\n",
        "\n",
        "# Input text\n",
        "text = '''NLP stands for Natural Language Processing.\n",
        "It is the branch of Artificial Intelligence that gives the ability to machine understand\n",
        "and process human languages. Human languages can be in the form of text or audio format.\n",
        "Natural Language Processing started in 1950 When Alan Mathison Turing published\n",
        "an article in the name Computing Machinery and Intelligence.\n",
        "It is based on Artificial intelligence. It talks about automatic interpretation and\n",
        "generation of natural language.\n",
        "As the technology evolved, different approaches have come to deal with NLP tasks.'''\n",
        "\n",
        "# Preprocessing\n",
        "stop_words = set(stopwords.words('english'))\n",
        "words_clean = [word.lower() for word in word_tokenize(text) if word.isalnum() and word.lower() not in stop_words]\n",
        "\n",
        "# Build co-occurrence graph\n",
        "window_size = 3  # Words are connected if they appear within a window of 3 words\n",
        "edges = []\n",
        "for i, word in enumerate(words_clean):\n",
        "    for j in range(i + 1, min(i + window_size, len(words_clean))):\n",
        "        edges.append((word, words_clean[j]))\n",
        "\n",
        "# Create graph\n",
        "graph = nx.Graph()\n",
        "graph.add_edges_from(edges)\n",
        "\n",
        "# Apply TextRank (PageRank) to rank words\n",
        "word_ranks = nx.pagerank(graph)\n",
        "\n",
        "# Rank words by their TextRank score\n",
        "ranked_words = sorted(word_ranks.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Display top 10 words\n",
        "top_words = ranked_words[:10]\n",
        "print(\"Top ranked words using TextRank:\")\n",
        "for word, score in top_words:\n",
        "    print(f\"{word}: {score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itEOQRSOBxXq",
        "outputId": "13baa796-9feb-4968-fbbf-d43ebac4c345"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top ranked words using TextRank:\n",
            "intelligence: 0.0453\n",
            "natural: 0.0448\n",
            "language: 0.0445\n",
            "artificial: 0.0307\n",
            "processing: 0.0302\n",
            "nlp: 0.0287\n",
            "human: 0.0272\n",
            "languages: 0.0271\n",
            "deal: 0.0244\n",
            "come: 0.0236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "from collections import defaultdict\n",
        "\n",
        "def get_textrank_scores_from_tokens(tokens, window_size=3):\n",
        "    \"\"\"\n",
        "    Applies TextRank (PageRank) to a list of preprocessed tokens.\n",
        "\n",
        "    Parameters:\n",
        "        tokens (list): List of preprocessed word tokens.\n",
        "        window_size (int): Window size for co-occurrence.\n",
        "\n",
        "    Returns:\n",
        "        dict: {word: TextRank score (rounded to 4 decimals)}\n",
        "    \"\"\"\n",
        "    if not isinstance(tokens, list) or len(tokens) < 2:\n",
        "        return {}\n",
        "\n",
        "    edges = []\n",
        "    for i, word in enumerate(tokens):\n",
        "        for j in range(i + 1, min(i + window_size, len(tokens))):\n",
        "            edges.append((word, tokens[j]))\n",
        "\n",
        "    graph = nx.Graph()\n",
        "    graph.add_edges_from(edges)\n",
        "\n",
        "    if graph.number_of_nodes() == 0:\n",
        "        return {}\n",
        "\n",
        "    word_ranks = nx.pagerank(graph)\n",
        "    word_ranks = {word: round(score, 3) for word, score in word_ranks.items()}\n",
        "    return word_ranks\n"
      ],
      "metadata": {
        "id": "9V98FkgeFMX3"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "# Load and parse the token list from CSV\n",
        "df = pd.read_csv(\"preprocessed_text.csv\")\n",
        "df['Preprocessed_Text'] = df['Preprocessed_Text'].apply(ast.literal_eval)\n",
        "\n",
        "# Apply the updated TextRank function\n",
        "df['TextRank_Word_Scores'] = df['Preprocessed_Text'].apply(get_textrank_scores_from_tokens)\n",
        "\n",
        "# Save results\n",
        "df[['Id', 'TextRank_Word_Scores']].to_csv(\"textrank_word_scores.csv\", index=False)\n",
        "print(\"✅ TextRank word-level scores saved to textrank_word_scores.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOpmr_1QZ2aG",
        "outputId": "1e5c1f63-9c7d-4382-97a9-948a52bd8b9b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CF-IOF word-level scores saved to cf_iof_word_scores.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CF-IOF"
      ],
      "metadata": {
        "id": "VlYeNOlCdIAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install senticnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVO69sPFdNHS",
        "outputId": "63172063-8b19-44b6-e5d8-5b6dcbdaffea"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: senticnet in /usr/local/lib/python3.11/dist-packages (1.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://github.com/facebookresearch/fastText/archive/v0.9.2.zip\n",
        "! unzip v0.9.2.zip\n",
        "! cd fastText-0.9.2\n",
        "! make\n",
        "!mingw32-make"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JClEo-23fSA8",
        "outputId": "c694dbe9-f6d7-4ef2-d482-194f1d61e36f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-12 16:01:58--  https://github.com/facebookresearch/fastText/archive/v0.9.2.zip\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/facebookresearch/fastText/zip/refs/tags/v0.9.2 [following]\n",
            "--2025-06-12 16:01:58--  https://codeload.github.com/facebookresearch/fastText/zip/refs/tags/v0.9.2\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.113.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.113.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘v0.9.2.zip’\n",
            "\n",
            "v0.9.2.zip              [   <=>              ]   4.17M  7.27MB/s    in 0.6s    \n",
            "\n",
            "2025-06-12 16:01:59 (7.27 MB/s) - ‘v0.9.2.zip’ saved [4369852]\n",
            "\n",
            "Archive:  v0.9.2.zip\n",
            "5b5943c118b0ec5fb9cd8d20587de2b2d3966dfe\n",
            "   creating: fastText-0.9.2/\n",
            "   creating: fastText-0.9.2/.circleci/\n",
            "  inflating: fastText-0.9.2/.circleci/cmake_test.sh  \n",
            "  inflating: fastText-0.9.2/.circleci/config.yml  \n",
            "  inflating: fastText-0.9.2/.circleci/gcc_test.sh  \n",
            "  inflating: fastText-0.9.2/.circleci/pip_test.sh  \n",
            "  inflating: fastText-0.9.2/.circleci/pull_data.sh  \n",
            "  inflating: fastText-0.9.2/.circleci/python_test.sh  \n",
            "  inflating: fastText-0.9.2/.circleci/run_locally.sh  \n",
            "  inflating: fastText-0.9.2/.circleci/setup_circleimg.sh  \n",
            "  inflating: fastText-0.9.2/.circleci/setup_debian.sh  \n",
            "  inflating: fastText-0.9.2/.gitignore  \n",
            "  inflating: fastText-0.9.2/CMakeLists.txt  \n",
            "  inflating: fastText-0.9.2/CODE_OF_CONDUCT.md  \n",
            "  inflating: fastText-0.9.2/CONTRIBUTING.md  \n",
            "  inflating: fastText-0.9.2/LICENSE  \n",
            "  inflating: fastText-0.9.2/MANIFEST.in  \n",
            "  inflating: fastText-0.9.2/Makefile  \n",
            "  inflating: fastText-0.9.2/README.md  \n",
            "   creating: fastText-0.9.2/alignment/\n",
            "  inflating: fastText-0.9.2/alignment/README.md  \n",
            "  inflating: fastText-0.9.2/alignment/align.py  \n",
            "  inflating: fastText-0.9.2/alignment/eval.py  \n",
            "  inflating: fastText-0.9.2/alignment/example.sh  \n",
            "  inflating: fastText-0.9.2/alignment/unsup_align.py  \n",
            "  inflating: fastText-0.9.2/alignment/unsup_multialign.py  \n",
            "  inflating: fastText-0.9.2/alignment/utils.py  \n",
            "  inflating: fastText-0.9.2/classification-example.sh  \n",
            "  inflating: fastText-0.9.2/classification-results.sh  \n",
            "   creating: fastText-0.9.2/crawl/\n",
            "  inflating: fastText-0.9.2/crawl/README.md  \n",
            "  inflating: fastText-0.9.2/crawl/dedup.cc  \n",
            "  inflating: fastText-0.9.2/crawl/download_crawl.sh  \n",
            "  inflating: fastText-0.9.2/crawl/filter_dedup.sh  \n",
            "  inflating: fastText-0.9.2/crawl/filter_utf8.cc  \n",
            "  inflating: fastText-0.9.2/crawl/process_wet_file.sh  \n",
            "   creating: fastText-0.9.2/docs/\n",
            "  inflating: fastText-0.9.2/docs/aligned-vectors.md  \n",
            "  inflating: fastText-0.9.2/docs/api.md  \n",
            "  inflating: fastText-0.9.2/docs/autotune.md  \n",
            "  inflating: fastText-0.9.2/docs/cheatsheet.md  \n",
            "  inflating: fastText-0.9.2/docs/crawl-vectors.md  \n",
            "  inflating: fastText-0.9.2/docs/dataset.md  \n",
            "  inflating: fastText-0.9.2/docs/english-vectors.md  \n",
            "  inflating: fastText-0.9.2/docs/faqs.md  \n",
            "  inflating: fastText-0.9.2/docs/language-identification.md  \n",
            "  inflating: fastText-0.9.2/docs/options.md  \n",
            "  inflating: fastText-0.9.2/docs/pretrained-vectors.md  \n",
            "  inflating: fastText-0.9.2/docs/python-module.md  \n",
            "  inflating: fastText-0.9.2/docs/references.md  \n",
            "  inflating: fastText-0.9.2/docs/supervised-models.md  \n",
            "  inflating: fastText-0.9.2/docs/supervised-tutorial.md  \n",
            "  inflating: fastText-0.9.2/docs/support.md  \n",
            "  inflating: fastText-0.9.2/docs/unsupervised-tutorials.md  \n",
            "  inflating: fastText-0.9.2/docs/webassembly-module.md  \n",
            "  inflating: fastText-0.9.2/download_model.py  \n",
            "  inflating: fastText-0.9.2/eval.py  \n",
            "  inflating: fastText-0.9.2/fasttext.pc.in  \n",
            "  inflating: fastText-0.9.2/get-wikimedia.sh  \n",
            "   creating: fastText-0.9.2/python/\n",
            "  inflating: fastText-0.9.2/python/README.md  \n",
            "  inflating: fastText-0.9.2/python/README.rst  \n",
            "   creating: fastText-0.9.2/python/benchmarks/\n",
            "  inflating: fastText-0.9.2/python/benchmarks/README.rst  \n",
            "  inflating: fastText-0.9.2/python/benchmarks/get_word_vector.py  \n",
            "   creating: fastText-0.9.2/python/doc/\n",
            "   creating: fastText-0.9.2/python/doc/examples/\n",
            "  inflating: fastText-0.9.2/python/doc/examples/FastTextEmbeddingBag.py  \n",
            "  inflating: fastText-0.9.2/python/doc/examples/bin_to_vec.py  \n",
            "  inflating: fastText-0.9.2/python/doc/examples/compute_accuracy.py  \n",
            "  inflating: fastText-0.9.2/python/doc/examples/get_vocab.py  \n",
            "  inflating: fastText-0.9.2/python/doc/examples/train_supervised.py  \n",
            "  inflating: fastText-0.9.2/python/doc/examples/train_unsupervised.py  \n",
            "   creating: fastText-0.9.2/python/fasttext_module/\n",
            "   creating: fastText-0.9.2/python/fasttext_module/fasttext/\n",
            "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/FastText.py  \n",
            "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/__init__.py  \n",
            "   creating: fastText-0.9.2/python/fasttext_module/fasttext/pybind/\n",
            "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/pybind/fasttext_pybind.cc  \n",
            "   creating: fastText-0.9.2/python/fasttext_module/fasttext/tests/\n",
            "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/tests/__init__.py  \n",
            "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/tests/test_configurations.py  \n",
            "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/tests/test_script.py  \n",
            "   creating: fastText-0.9.2/python/fasttext_module/fasttext/util/\n",
            "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/util/__init__.py  \n",
            "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/util/util.py  \n",
            "  inflating: fastText-0.9.2/quantization-example.sh  \n",
            "  inflating: fastText-0.9.2/reduce_model.py  \n",
            "  inflating: fastText-0.9.2/runtests.py  \n",
            "   creating: fastText-0.9.2/scripts/\n",
            "   creating: fastText-0.9.2/scripts/kbcompletion/\n",
            "  inflating: fastText-0.9.2/scripts/kbcompletion/README.md  \n",
            "  inflating: fastText-0.9.2/scripts/kbcompletion/data.sh  \n",
            "  inflating: fastText-0.9.2/scripts/kbcompletion/eval.cpp  \n",
            "  inflating: fastText-0.9.2/scripts/kbcompletion/fb15k.sh  \n",
            "  inflating: fastText-0.9.2/scripts/kbcompletion/fb15k237.sh  \n",
            "  inflating: fastText-0.9.2/scripts/kbcompletion/svo.sh  \n",
            "  inflating: fastText-0.9.2/scripts/kbcompletion/wn18.sh  \n",
            "   creating: fastText-0.9.2/scripts/quantization/\n",
            "  inflating: fastText-0.9.2/scripts/quantization/quantization-results.sh  \n",
            " extracting: fastText-0.9.2/setup.cfg  \n",
            "  inflating: fastText-0.9.2/setup.py  \n",
            "   creating: fastText-0.9.2/src/\n",
            "  inflating: fastText-0.9.2/src/args.cc  \n",
            "  inflating: fastText-0.9.2/src/args.h  \n",
            "  inflating: fastText-0.9.2/src/autotune.cc  \n",
            "  inflating: fastText-0.9.2/src/autotune.h  \n",
            "  inflating: fastText-0.9.2/src/densematrix.cc  \n",
            "  inflating: fastText-0.9.2/src/densematrix.h  \n",
            "  inflating: fastText-0.9.2/src/dictionary.cc  \n",
            "  inflating: fastText-0.9.2/src/dictionary.h  \n",
            "  inflating: fastText-0.9.2/src/fasttext.cc  \n",
            "  inflating: fastText-0.9.2/src/fasttext.h  \n",
            "  inflating: fastText-0.9.2/src/loss.cc  \n",
            "  inflating: fastText-0.9.2/src/loss.h  \n",
            "  inflating: fastText-0.9.2/src/main.cc  \n",
            "  inflating: fastText-0.9.2/src/matrix.cc  \n",
            "  inflating: fastText-0.9.2/src/matrix.h  \n",
            "  inflating: fastText-0.9.2/src/meter.cc  \n",
            "  inflating: fastText-0.9.2/src/meter.h  \n",
            "  inflating: fastText-0.9.2/src/model.cc  \n",
            "  inflating: fastText-0.9.2/src/model.h  \n",
            "  inflating: fastText-0.9.2/src/productquantizer.cc  \n",
            "  inflating: fastText-0.9.2/src/productquantizer.h  \n",
            "  inflating: fastText-0.9.2/src/quantmatrix.cc  \n",
            "  inflating: fastText-0.9.2/src/quantmatrix.h  \n",
            "  inflating: fastText-0.9.2/src/real.h  \n",
            "  inflating: fastText-0.9.2/src/utils.cc  \n",
            "  inflating: fastText-0.9.2/src/utils.h  \n",
            "  inflating: fastText-0.9.2/src/vector.cc  \n",
            "  inflating: fastText-0.9.2/src/vector.h  \n",
            "   creating: fastText-0.9.2/tests/\n",
            "  inflating: fastText-0.9.2/tests/fetch_test_data.sh  \n",
            "   creating: fastText-0.9.2/webassembly/\n",
            "  inflating: fastText-0.9.2/webassembly/README.md  \n",
            "   creating: fastText-0.9.2/webassembly/doc/\n",
            "   creating: fastText-0.9.2/webassembly/doc/examples/\n",
            "  inflating: fastText-0.9.2/webassembly/doc/examples/misc.html  \n",
            "  inflating: fastText-0.9.2/webassembly/doc/examples/predict.html  \n",
            "  inflating: fastText-0.9.2/webassembly/doc/examples/train_supervised.html  \n",
            "  inflating: fastText-0.9.2/webassembly/doc/examples/train_unsupervised.html  \n",
            "  inflating: fastText-0.9.2/webassembly/fasttext.js  \n",
            "  inflating: fastText-0.9.2/webassembly/fasttext_wasm.cc  \n",
            "   creating: fastText-0.9.2/website/\n",
            "  inflating: fastText-0.9.2/website/README.md  \n",
            "   creating: fastText-0.9.2/website/blog/\n",
            "  inflating: fastText-0.9.2/website/blog/2016-08-18-blog-post.md  \n",
            "  inflating: fastText-0.9.2/website/blog/2017-05-02-blog-post.md  \n",
            "  inflating: fastText-0.9.2/website/blog/2017-10-02-blog-post.md  \n",
            "  inflating: fastText-0.9.2/website/blog/2019-06-25-blog-post.md  \n",
            "   creating: fastText-0.9.2/website/core/\n",
            "  inflating: fastText-0.9.2/website/core/Footer.js  \n",
            "  inflating: fastText-0.9.2/website/package.json  \n",
            "   creating: fastText-0.9.2/website/pages/\n",
            "   creating: fastText-0.9.2/website/pages/en/\n",
            "  inflating: fastText-0.9.2/website/pages/en/index.js  \n",
            "  inflating: fastText-0.9.2/website/sidebars.json  \n",
            "  inflating: fastText-0.9.2/website/siteConfig.js  \n",
            "   creating: fastText-0.9.2/website/static/\n",
            "   creating: fastText-0.9.2/website/static/docs/\n",
            "   creating: fastText-0.9.2/website/static/docs/en/\n",
            "   creating: fastText-0.9.2/website/static/docs/en/html/\n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/.classfasttext_1_1QMatrix-members.html.i4eKqy  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/annotated.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/annotated_dup.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/args_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/args_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/args_8h.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/args_8h_source.html  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/bc_s.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/bdwn.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classes.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Args-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Args.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Args.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Dictionary-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Dictionary.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Dictionary.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1FastText-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1FastText.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1FastText.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Matrix-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Matrix.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Matrix.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Model-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Model.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Model.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1ProductQuantizer-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1ProductQuantizer.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1ProductQuantizer.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1QMatrix-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1QMatrix.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1QMatrix.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Vector-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Vector.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Vector.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/closed.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/dictionary_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/dictionary_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/dictionary_8h.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/dictionary_8h_source.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/dir_68267d1309a1af8e8297ef4c3efbcdba.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/dir_68267d1309a1af8e8297ef4c3efbcdba.js  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/doc.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/doxygen.css  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/doxygen.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/dynsections.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/fasttext_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/fasttext_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/fasttext_8h.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/fasttext_8h_source.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/favicon.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/files.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/files.js  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/folderclosed.png  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/folderopen.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_0x7e.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_b.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_c.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_d.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_dup.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_e.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_f.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_func.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_g.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_i.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_k.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_l.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_m.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_n.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_o.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_p.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_q.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_r.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_s.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_t.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_u.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_v.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_vars.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_w.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_z.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/globals.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/globals_defs.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/globals_func.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/index.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/jquery.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/main_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/main_8cc.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/matrix_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/matrix_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/matrix_8h_source.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/menu.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/menudata.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/model_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/model_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/model_8h.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/model_8h_source.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacefasttext.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacefasttext.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacefasttext_1_1utils.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacemembers.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacemembers_enum.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacemembers_func.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacemembers_type.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/namespaces.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/namespaces.js  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/nav_f.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/nav_g.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/nav_h.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/navtree.css  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/navtree.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/navtreedata.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/navtreeindex0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/navtreeindex1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/open.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/productquantizer_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/productquantizer_8cc.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/productquantizer_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/productquantizer_8h_source.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/qmatrix_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/qmatrix_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/qmatrix_8h_source.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/real_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/real_8h.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/real_8h_source.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/resize.js  \n",
            "   creating: fastText-0.9.2/website/static/docs/en/html/search/\n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/search/.files_7.html.StRRNc  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/search/.variables_a.html.1MGQ27  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_1.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_10.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_10.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_11.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_11.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_12.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_12.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_13.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_13.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_14.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_14.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_15.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_15.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_16.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_16.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_17.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_17.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_2.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_2.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_3.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_3.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_4.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_4.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_5.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_5.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_6.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_6.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_7.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_7.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_8.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_8.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_9.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_9.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_a.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_a.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_b.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_b.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_c.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_c.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_d.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_d.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_e.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_e.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_f.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_f.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_1.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_2.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_2.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_3.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_3.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_4.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_4.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_5.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_5.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_6.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_6.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_7.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_7.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_8.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_8.js  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/search/close.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_1.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_2.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_2.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_3.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_3.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_1.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_2.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_2.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_1.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_2.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_2.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_3.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_3.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_4.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_4.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_5.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_5.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_1.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_2.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_2.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_3.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_3.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_4.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_4.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_5.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_5.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_6.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_6.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_7.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_7.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_8.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_8.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_1.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_10.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_10.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_11.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_11.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_12.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_12.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_13.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_13.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_14.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_14.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_15.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_15.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_16.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_16.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_17.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_17.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_2.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_2.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_3.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_3.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_4.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_4.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_5.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_5.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_6.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_6.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_7.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_7.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_8.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_8.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_9.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_9.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_a.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_a.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_b.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_b.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_c.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_c.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_d.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_d.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_e.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_e.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_f.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_f.js  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/search/mag_sel.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/namespaces_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/namespaces_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/nomatches.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/search.css  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/search.js  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/search/search_l.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/search_m.png  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/search/search_r.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/searchdata.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/typedefs_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/typedefs_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/typedefs_1.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/typedefs_1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_1.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_10.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_10.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_11.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_11.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_12.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_12.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_13.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_13.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_2.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_2.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_3.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_3.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_4.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_4.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_5.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_5.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_6.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_6.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_7.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_7.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_8.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_8.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_9.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_9.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_a.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_a.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_b.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_b.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_c.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_c.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_d.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_d.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_e.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_e.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_f.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_f.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/splitbar.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1Node-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1Node.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1Node.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1entry-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1entry.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1entry.js  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/sync_off.png  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/sync_on.png  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/tab_a.png  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/tab_b.png  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/tab_h.png  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/tab_s.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/tabs.css  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/utils_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/utils_8cc.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/utils_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/utils_8h.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/utils_8h_source.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/vector_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/vector_8cc.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/vector_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/vector_8h.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/vector_8h_source.html  \n",
            "  inflating: fastText-0.9.2/website/static/fasttext.css  \n",
            "   creating: fastText-0.9.2/website/static/img/\n",
            "   creating: fastText-0.9.2/website/static/img/authors/\n",
            "  inflating: fastText-0.9.2/website/static/img/authors/armand_joulin.jpg  \n",
            "  inflating: fastText-0.9.2/website/static/img/authors/christian_puhrsch.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/authors/edouard_grave.jpeg  \n",
            "  inflating: fastText-0.9.2/website/static/img/authors/piotr_bojanowski.jpg  \n",
            "  inflating: fastText-0.9.2/website/static/img/authors/tomas_mikolov.jpg  \n",
            "   creating: fastText-0.9.2/website/static/img/blog/\n",
            "  inflating: fastText-0.9.2/website/static/img/blog/2016-08-18-blog-post-img1.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/blog/2016-08-18-blog-post-img2.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/blog/2017-05-02-blog-post-img1.jpg  \n",
            "  inflating: fastText-0.9.2/website/static/img/blog/2017-05-02-blog-post-img2.jpg  \n",
            "  inflating: fastText-0.9.2/website/static/img/blog/2017-10-02-blog-post-img1.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/cbo_vs_skipgram.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-api.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-bg-web.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-color-square.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-color-web.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-faq.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-tutorial.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-white-web.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/fasttext-logo-color-web.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/fasttext-logo-white-web.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/logo-color.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/model-black.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/model-blue.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/model-red.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/ogimage.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/oss_logo.png  \n",
            "  inflating: fastText-0.9.2/website/static/tabber.js  \n",
            "  inflating: fastText-0.9.2/wikifil.pl  \n",
            "  inflating: fastText-0.9.2/word-vector-example.sh  \n",
            "make: *** No targets specified and no makefile found.  Stop.\n",
            "/bin/bash: line 1: mingw32-make: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext\n",
        "!git clone https://github.com/facebookresearch/fastText.git\n",
        "%cd fastText\n",
        "!pip install .\n"
      ],
      "metadata": {
        "id": "_BTJ7VrBXzfs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "outputId": "f7e58f19-1da5-4236-e791-2e1227c15ec7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.11/dist-packages (0.9.2)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.11/dist-packages (from fasttext) (2.13.6)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fasttext) (2.0.2)\n",
            "fatal: destination path 'fastText' already exists and is not an empty directory.\n",
            "/content/fastText\n",
            "Processing /content/fastText\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.11/dist-packages (from fasttext==0.9.2) (2.13.6)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext==0.9.2) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fasttext==0.9.2) (2.0.2)\n",
            "Building wheels for collected packages: fasttext\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25h"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'PosixPath' object has no attribute '_str'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-4160654600>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'git clone https://github.com/facebookresearch/fastText.git'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fastText'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install .'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m       \u001b[0m_pip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_send_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36mprint_previous_import_warning\u001b[0;34m(output)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;34m\"\"\"Prints a warning about previously imported packages.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0mpackages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpackages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# display a list of packages using the colab-display-data mimetype, which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_previously_imported_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;34m\"\"\"List all previously imported packages from a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m   \u001b[0minstalled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_toplevel_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstalled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_extract_toplevel_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;34m\"\"\"Extract the list of toplevel packages associated with a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mtoplevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages_distributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mtoplevel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mpackages_distributions\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1073\u001b[0m     \u001b[0mpkg_to_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_top_level_declared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_top_level_inferred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1076\u001b[0m             \u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m_top_level_inferred\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m   1085\u001b[0m     return {\n\u001b[1;32m   1086\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malways_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffix\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\".py\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m     }\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/importlib_metadata/__init__.py\u001b[0m in \u001b[0;36mfiles\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m         return skip_missing_files(\n\u001b[0m\u001b[1;32m    605\u001b[0m             make_files(\n\u001b[1;32m    606\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_files_distinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/importlib_metadata/_functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(param, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/importlib_metadata/__init__.py\u001b[0m in \u001b[0;36mskip_missing_files\u001b[0;34m(package_paths)\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/importlib_metadata/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1233\u001b[0m         \"\"\"\n\u001b[1;32m   1234\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ignore_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36mstat\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mdoes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \"\"\"\n\u001b[0;32m-> 1013\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36m__fspath__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mas_posix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             self._str = self._format_parsed_parts(self._drv, self._root,\n\u001b[0m\u001b[1;32m    543\u001b[0m                                                   self._parts) or '.'\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36m_format_parsed_parts\u001b[0;34m(cls, drv, root, parts)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_format_parsed_parts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdrv\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdrv\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flavour\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flavour\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oLsha22bYaVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install senticnet fasttext tabulate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWWO4oRbWJt3",
        "outputId": "04912940-3b55-41c6-b72b-19a9bf04ef96"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: senticnet in /usr/local/lib/python3.11/dist-packages (1.6)\n",
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.11/dist-packages (0.9.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.11/dist-packages (from fasttext) (2.13.6)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fasttext) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a pre-trained FastText word embedding model\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
        "!gzip -d cc.en.300.bin.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k48XaiQ9XGf2",
        "outputId": "48671fef-8b44-469d-c512-5129fb484940"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-12 16:09:16--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 18.154.144.87, 18.154.144.102, 18.154.144.74, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|18.154.144.87|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4503593528 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.en.300.bin.gz’\n",
            "\n",
            "cc.en.300.bin.gz    100%[===================>]   4.19G   139MB/s    in 39s     \n",
            "\n",
            "2025-06-12 16:09:55 (111 MB/s) - ‘cc.en.300.bin.gz’ saved [4503593528/4503593528]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "\n",
        "# Load the pre-trained FastText word embedding model\n",
        "fasttext_model = fasttext.load_model(\"cc.en.300.bin\")"
      ],
      "metadata": {
        "id": "_RZry_4wXSWT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from senticnet.senticnet import SenticNet\n",
        "import fasttext\n",
        "\n",
        "import numpy as np\n",
        "sn = SenticNet()\n",
        "def get_polarity(word):\n",
        "    try:\n",
        "        # Check SenticNet for polarity\n",
        "        polarity = sn.polarity_value(word)\n",
        "        print(f\"Found in SenticNet: {word} -> {polarity}\")\n",
        "        return float(polarity)  # Convert polarity to float\n",
        "    except KeyError:\n",
        "        # If word is not found in SenticNet, use FastText for prediction\n",
        "        print(f\"Not found in SenticNet. Using FastText for: {word}\")\n",
        "        try:\n",
        "            # Get the word vector from FastText\n",
        "            word_vector = fasttext_model.get_word_vector(word)\n",
        "            # Calculate polarity as the sum of the word vector components\n",
        "            polarity = np.sum(word_vector)\n",
        "            return polarity\n",
        "        except KeyError:\n",
        "            # If word is not in FastText vocabulary, return neutral polarity\n",
        "            return 0.0"
      ],
      "metadata": {
        "id": "lMUO3dLWqxRw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "from collections import defaultdict # Import defaultdict from collections\n",
        "import numpy as np\n",
        "from tabulate import tabulate\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from tabulate import tabulate\n",
        "\n",
        "\n",
        "def get_word_polarities(text):\n",
        "    bins = np.linspace(-1, 1, num=6)  # 6 edges create 5 bins\n",
        "    labels = [1, 2, 3, 4, 5]  # Bin labels\n",
        "\n",
        "    words = text.split()\n",
        "    word_polarities = []\n",
        "    feature_bin_map = {}  # Store word and assigned bin\n",
        "\n",
        "    for word in words:\n",
        "        polarity = get_polarity(word)\n",
        "        if polarity < -0.6:\n",
        "            bin_value = 1\n",
        "        elif polarity < -0.2:\n",
        "            bin_value = 2\n",
        "        elif polarity < 0.2:\n",
        "            bin_value = 3\n",
        "        elif polarity < 0.6:\n",
        "            bin_value = 4\n",
        "        else:\n",
        "            bin_value = 5\n",
        "        word_polarities.append([word, polarity, bin_value])\n",
        "        feature_bin_map[word] = bin_value\n",
        "\n",
        "    print(tabulate(word_polarities, headers=[\"Word\", \"Polarity\", \"Bin\"], tablefmt=\"pretty\"))\n",
        "    return feature_bin_map  # Return dictionary of words and assigned bins\n",
        "\n",
        "def compute_cf_iof(reviews):\n",
        "    feature_counts = defaultdict(lambda: defaultdict(int))  # {feature: {bin: count}}\n",
        "    total_bin_counts = defaultdict(int)  # {bin: total count of all features}\n",
        "    review_counts = defaultdict(int)  # {feature: number of reviews containing feature}\n",
        "\n",
        "    for review in reviews:\n",
        "        feature_bin_map = get_word_polarities(review)\n",
        "        seen_features = set()  # Track features seen in this review\n",
        "\n",
        "        for feature, bin_value in feature_bin_map.items():\n",
        "            feature_counts[feature][bin_value] += 1\n",
        "            total_bin_counts[bin_value] += 1\n",
        "            if feature not in seen_features:\n",
        "                review_counts[feature] += 1\n",
        "                seen_features.add(feature)\n",
        "\n",
        "    # Compute CF-IOF Scores\n",
        "    cf_iof_scores = {}\n",
        "    for feature, bins in feature_counts.items():\n",
        "        cf_iof_score = 0\n",
        "        for bin_value, n_ij in bins.items():\n",
        "            if total_bin_counts[bin_value] > 0:\n",
        "                tf = n_ij / total_bin_counts[bin_value]  # Term frequency\n",
        "                idf = np.log(review_counts[feature] + 1)  # Log of number of reviews containing feature\n",
        "                cf_iof_score += tf * idf\n",
        "\n",
        "        cf_iof_scores[feature] = cf_iof_score\n",
        "\n",
        "    # Display results\n",
        "    sorted_scores = sorted(cf_iof_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    print(tabulate(sorted_scores, headers=[\"Feature\", \"CF-IOF Score\"], tablefmt=\"pretty\"))\n",
        "\n",
        "    return cf_iof_scores\n",
        "\n",
        "# Example reviews dataset\n",
        "reviews = [\n",
        "    \"NLP is a great field of study with amazing potential.\",\n",
        "    \"Sentiment analysis is crucial for understanding human emotions.\",\n",
        "    \"Natural Language Processing is an evolving technology that relies on AI.\",\n",
        "    \"Machine learning and deep learning improve NLP models significantly.\",\n",
        "    \"The advancements in AI are making NLP more efficient.\"\n",
        "]\n",
        "\n",
        "# Compute CF-IOF scores\n",
        "compute_cf_iof(reviews)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJIdu_emX2Ym",
        "outputId": "d547b5fe-99bc-44fe-a733-692a38a7df2c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not found in SenticNet. Using FastText for: NLP\n",
            "Not found in SenticNet. Using FastText for: is\n",
            "Not found in SenticNet. Using FastText for: a\n",
            "Found in SenticNet: great -> 0.857\n",
            "Not found in SenticNet. Using FastText for: field\n",
            "Not found in SenticNet. Using FastText for: of\n",
            "Not found in SenticNet. Using FastText for: study\n",
            "Not found in SenticNet. Using FastText for: with\n",
            "Found in SenticNet: amazing -> 0.956\n",
            "Not found in SenticNet. Using FastText for: potential.\n",
            "+------------+----------------------+-----+\n",
            "|    Word    |       Polarity       | Bin |\n",
            "+------------+----------------------+-----+\n",
            "|    NLP     |  0.4682713449001312  |  4  |\n",
            "|     is     |  -4.307405948638916  |  1  |\n",
            "|     a      |  1.995366096496582   |  5  |\n",
            "|   great    |        0.857         |  5  |\n",
            "|   field    | -0.9385746121406555  |  1  |\n",
            "|     of     |  2.585928201675415   |  5  |\n",
            "|   study    | 0.40166041254997253  |  4  |\n",
            "|    with    |  0.2396959662437439  |  4  |\n",
            "|  amazing   |        0.956         |  5  |\n",
            "| potential. | -0.43885117769241333 |  2  |\n",
            "+------------+----------------------+-----+\n",
            "Not found in SenticNet. Using FastText for: Sentiment\n",
            "Found in SenticNet: analysis -> 0.17\n",
            "Not found in SenticNet. Using FastText for: is\n",
            "Found in SenticNet: crucial -> 0.849\n",
            "Not found in SenticNet. Using FastText for: for\n",
            "Found in SenticNet: understanding -> 0.744\n",
            "Not found in SenticNet. Using FastText for: human\n",
            "Not found in SenticNet. Using FastText for: emotions.\n",
            "+---------------+---------------------+-----+\n",
            "|     Word      |      Polarity       | Bin |\n",
            "+---------------+---------------------+-----+\n",
            "|   Sentiment   | 0.5437065362930298  |  4  |\n",
            "|   analysis    |        0.17         |  3  |\n",
            "|      is       | -4.307405948638916  |  1  |\n",
            "|    crucial    |        0.849        |  5  |\n",
            "|      for      | 0.3772526979446411  |  4  |\n",
            "| understanding |        0.744        |  5  |\n",
            "|     human     | 0.8202881217002869  |  5  |\n",
            "|   emotions.   | 0.14937758445739746 |  3  |\n",
            "+---------------+---------------------+-----+\n",
            "Not found in SenticNet. Using FastText for: Natural\n",
            "Not found in SenticNet. Using FastText for: Language\n",
            "Not found in SenticNet. Using FastText for: Processing\n",
            "Not found in SenticNet. Using FastText for: is\n",
            "Not found in SenticNet. Using FastText for: an\n",
            "Not found in SenticNet. Using FastText for: evolving\n",
            "Found in SenticNet: technology -> 0.94\n",
            "Not found in SenticNet. Using FastText for: that\n",
            "Not found in SenticNet. Using FastText for: relies\n",
            "Not found in SenticNet. Using FastText for: on\n",
            "Not found in SenticNet. Using FastText for: AI.\n",
            "+------------+----------------------+-----+\n",
            "|    Word    |       Polarity       | Bin |\n",
            "+------------+----------------------+-----+\n",
            "|  Natural   |  1.1517168283462524  |  5  |\n",
            "|  Language  |  0.767330527305603   |  5  |\n",
            "| Processing | 0.29067710041999817  |  4  |\n",
            "|     is     |  -4.307405948638916  |  1  |\n",
            "|     an     |  8.546649932861328   |  5  |\n",
            "|  evolving  | -0.47253865003585815 |  2  |\n",
            "| technology |         0.94         |  5  |\n",
            "|    that    | -1.1141571998596191  |  1  |\n",
            "|   relies   | -0.9642812013626099  |  1  |\n",
            "|     on     |  4.7638678550720215  |  5  |\n",
            "|    AI.     |  2.6520838737487793  |  5  |\n",
            "+------------+----------------------+-----+\n",
            "Not found in SenticNet. Using FastText for: Machine\n",
            "Found in SenticNet: learning -> 0.824\n",
            "Not found in SenticNet. Using FastText for: and\n",
            "Found in SenticNet: deep -> 0.9\n",
            "Found in SenticNet: learning -> 0.824\n",
            "Found in SenticNet: improve -> 0.151\n",
            "Not found in SenticNet. Using FastText for: NLP\n",
            "Found in SenticNet: models -> 0.9\n",
            "Not found in SenticNet. Using FastText for: significantly.\n",
            "+----------------+----------------------+-----+\n",
            "|      Word      |       Polarity       | Bin |\n",
            "+----------------+----------------------+-----+\n",
            "|    Machine     | -0.8418774604797363  |  1  |\n",
            "|    learning    |        0.824         |  5  |\n",
            "|      and       | -0.22583289444446564 |  2  |\n",
            "|      deep      |         0.9          |  5  |\n",
            "|    learning    |        0.824         |  5  |\n",
            "|    improve     |        0.151         |  3  |\n",
            "|      NLP       |  0.4682713449001312  |  4  |\n",
            "|     models     |         0.9          |  5  |\n",
            "| significantly. | -0.38353946805000305 |  2  |\n",
            "+----------------+----------------------+-----+\n",
            "Not found in SenticNet. Using FastText for: The\n",
            "Not found in SenticNet. Using FastText for: advancements\n",
            "Not found in SenticNet. Using FastText for: in\n",
            "Not found in SenticNet. Using FastText for: AI\n",
            "Not found in SenticNet. Using FastText for: are\n",
            "Not found in SenticNet. Using FastText for: making\n",
            "Not found in SenticNet. Using FastText for: NLP\n",
            "Not found in SenticNet. Using FastText for: more\n",
            "Not found in SenticNet. Using FastText for: efficient.\n",
            "+--------------+---------------------+-----+\n",
            "|     Word     |      Polarity       | Bin |\n",
            "+--------------+---------------------+-----+\n",
            "|     The      |  1.135579228401184  |  5  |\n",
            "| advancements | -0.4655790627002716 |  2  |\n",
            "|      in      | -0.8389050960540771 |  1  |\n",
            "|      AI      | 0.42225170135498047 |  4  |\n",
            "|     are      | -2.473569393157959  |  1  |\n",
            "|    making    | -1.5136889219284058 |  1  |\n",
            "|     NLP      | 0.4682713449001312  |  4  |\n",
            "|     more     | -1.556436538696289  |  1  |\n",
            "|  efficient.  | -0.6089794635772705 |  1  |\n",
            "+--------------+---------------------+-----+\n",
            "+----------------+----------------------+\n",
            "|    Feature     |     CF-IOF Score     |\n",
            "+----------------+----------------------+\n",
            "|      NLP       | 0.46209812037329684  |\n",
            "|       is       | 0.34657359027997264  |\n",
            "|    analysis    | 0.23104906018664842  |\n",
            "|   emotions.    | 0.23104906018664842  |\n",
            "|    improve     | 0.23104906018664842  |\n",
            "|   potential.   | 0.13862943611198905  |\n",
            "|    evolving    | 0.13862943611198905  |\n",
            "|      and       | 0.13862943611198905  |\n",
            "| significantly. | 0.13862943611198905  |\n",
            "|  advancements  | 0.13862943611198905  |\n",
            "|     study      | 0.07701635339554948  |\n",
            "|      with      | 0.07701635339554948  |\n",
            "|   Sentiment    | 0.07701635339554948  |\n",
            "|      for       | 0.07701635339554948  |\n",
            "|   Processing   | 0.07701635339554948  |\n",
            "|       AI       | 0.07701635339554948  |\n",
            "|     field      | 0.057762265046662105 |\n",
            "|      that      | 0.057762265046662105 |\n",
            "|     relies     | 0.057762265046662105 |\n",
            "|    Machine     | 0.057762265046662105 |\n",
            "|       in       | 0.057762265046662105 |\n",
            "|      are       | 0.057762265046662105 |\n",
            "|     making     | 0.057762265046662105 |\n",
            "|      more      | 0.057762265046662105 |\n",
            "|   efficient.   | 0.057762265046662105 |\n",
            "|       a        | 0.04077336356234972  |\n",
            "|     great      | 0.04077336356234972  |\n",
            "|       of       | 0.04077336356234972  |\n",
            "|    amazing     | 0.04077336356234972  |\n",
            "|    crucial     | 0.04077336356234972  |\n",
            "| understanding  | 0.04077336356234972  |\n",
            "|     human      | 0.04077336356234972  |\n",
            "|    Natural     | 0.04077336356234972  |\n",
            "|    Language    | 0.04077336356234972  |\n",
            "|       an       | 0.04077336356234972  |\n",
            "|   technology   | 0.04077336356234972  |\n",
            "|       on       | 0.04077336356234972  |\n",
            "|      AI.       | 0.04077336356234972  |\n",
            "|    learning    | 0.04077336356234972  |\n",
            "|      deep      | 0.04077336356234972  |\n",
            "|     models     | 0.04077336356234972  |\n",
            "|      The       | 0.04077336356234972  |\n",
            "+----------------+----------------------+\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'NLP': np.float64(0.46209812037329684),\n",
              " 'is': np.float64(0.34657359027997264),\n",
              " 'a': np.float64(0.04077336356234972),\n",
              " 'great': np.float64(0.04077336356234972),\n",
              " 'field': np.float64(0.057762265046662105),\n",
              " 'of': np.float64(0.04077336356234972),\n",
              " 'study': np.float64(0.07701635339554948),\n",
              " 'with': np.float64(0.07701635339554948),\n",
              " 'amazing': np.float64(0.04077336356234972),\n",
              " 'potential.': np.float64(0.13862943611198905),\n",
              " 'Sentiment': np.float64(0.07701635339554948),\n",
              " 'analysis': np.float64(0.23104906018664842),\n",
              " 'crucial': np.float64(0.04077336356234972),\n",
              " 'for': np.float64(0.07701635339554948),\n",
              " 'understanding': np.float64(0.04077336356234972),\n",
              " 'human': np.float64(0.04077336356234972),\n",
              " 'emotions.': np.float64(0.23104906018664842),\n",
              " 'Natural': np.float64(0.04077336356234972),\n",
              " 'Language': np.float64(0.04077336356234972),\n",
              " 'Processing': np.float64(0.07701635339554948),\n",
              " 'an': np.float64(0.04077336356234972),\n",
              " 'evolving': np.float64(0.13862943611198905),\n",
              " 'technology': np.float64(0.04077336356234972),\n",
              " 'that': np.float64(0.057762265046662105),\n",
              " 'relies': np.float64(0.057762265046662105),\n",
              " 'on': np.float64(0.04077336356234972),\n",
              " 'AI.': np.float64(0.04077336356234972),\n",
              " 'Machine': np.float64(0.057762265046662105),\n",
              " 'learning': np.float64(0.04077336356234972),\n",
              " 'and': np.float64(0.13862943611198905),\n",
              " 'deep': np.float64(0.04077336356234972),\n",
              " 'improve': np.float64(0.23104906018664842),\n",
              " 'models': np.float64(0.04077336356234972),\n",
              " 'significantly.': np.float64(0.13862943611198905),\n",
              " 'The': np.float64(0.04077336356234972),\n",
              " 'advancements': np.float64(0.13862943611198905),\n",
              " 'in': np.float64(0.057762265046662105),\n",
              " 'AI': np.float64(0.07701635339554948),\n",
              " 'are': np.float64(0.057762265046662105),\n",
              " 'making': np.float64(0.057762265046662105),\n",
              " 'more': np.float64(0.057762265046662105),\n",
              " 'efficient.': np.float64(0.057762265046662105)}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from senticnet.senticnet import SenticNet\n",
        "import fasttext\n",
        "import numpy as np\n",
        "\n",
        "# Load SenticNet and FastText model (ensure you have cc.en.300.bin)\n",
        "sn = SenticNet()\n",
        "fasttext_model = fasttext.load_model(\"cc.en.300.bin\")\n",
        "\n",
        "def get_polarity(word):\n",
        "    try:\n",
        "        return float(sn.polarity_value(word))\n",
        "    except KeyError:\n",
        "        try:\n",
        "            vec = fasttext_model.get_word_vector(word)\n",
        "            return np.sum(vec)\n",
        "        except:\n",
        "            return 0.0\n",
        "\n",
        "def get_polarity_bin(polarity):\n",
        "    if polarity < -0.6:\n",
        "        return 1\n",
        "    elif polarity < -0.2:\n",
        "        return 2\n",
        "    elif polarity < 0.2:\n",
        "        return 3\n",
        "    elif polarity < 0.6:\n",
        "        return 4\n",
        "    else:\n",
        "        return 5\n"
      ],
      "metadata": {
        "id": "l4h95OgydHCi"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def compute_cf_iof_scores(token_lists):\n",
        "    \"\"\"\n",
        "    Compute global CF-IOF scores for all features across reviews.\n",
        "\n",
        "    token_lists: List of lists, where each sublist is a tokenized review.\n",
        "\n",
        "    Returns:\n",
        "        dict of {feature: CF-IOF score}\n",
        "    \"\"\"\n",
        "    feature_counts = defaultdict(lambda: defaultdict(int))  # {feature: {bin: count}}\n",
        "    total_bin_counts = defaultdict(int)                     # {bin: total count across all features}\n",
        "    review_counts = defaultdict(int)                        # {feature: number of reviews it appears in}\n",
        "\n",
        "    for tokens in token_lists:\n",
        "        seen_features = set()\n",
        "        for word in tokens:\n",
        "            polarity = get_polarity(word)\n",
        "            bin_value = get_polarity_bin(polarity)\n",
        "\n",
        "            feature_counts[word][bin_value] += 1\n",
        "            total_bin_counts[bin_value] += 1\n",
        "            if word not in seen_features:\n",
        "                review_counts[word] += 1\n",
        "                seen_features.add(word)\n",
        "\n",
        "    # Calculate final CF-IOF score\n",
        "    cf_iof_scores = {}\n",
        "    for word, bin_data in feature_counts.items():\n",
        "        score = 0\n",
        "        for bin_value, freq in bin_data.items():\n",
        "            tf = freq / total_bin_counts[bin_value]\n",
        "            idf = np.log(1 + review_counts[word])\n",
        "            score += tf * idf\n",
        "        cf_iof_scores[word] = round(score, 4)\n",
        "\n",
        "    return cf_iof_scores\n"
      ],
      "metadata": {
        "id": "NAVCq8ZXdHtR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_lists = df['Preprocessed_Text'].tolist()\n",
        "cf_iof_scores = compute_cf_iof_scores(token_lists)\n",
        "\n",
        "# Step 4: Map per-review word-level CF-IOF scores\n",
        "df['CF_IOF_Word_Scores'] = df['Preprocessed_Text'].apply(\n",
        "    lambda tokens: {word: cf_iof_scores.get(word, 0.0) for word in tokens}\n",
        ")\n",
        "\n",
        "# Step 5: Save only Id + word scores in original order\n",
        "df[['Id', 'CF_IOF_Word_Scores']].to_csv(\"cf_iof_word_scores.csv\", index=False)\n",
        "print(\"✅ CF-IOF word-level scores saved to cf_iof_word_scores.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cozVXAvNdL6H",
        "outputId": "8aa4b8c2-6f15-4a2c-ef40-39542a5e14a0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CF-IOF word-level scores saved to cf_iof_word_scores.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PSO"
      ],
      "metadata": {
        "id": "3M0rszN-IH3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyswarms\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZIjw60sfNNO",
        "outputId": "a6a96145-4502-47a9-ce89-a75cb5ec9971"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyswarms\n",
            "  Downloading pyswarms-1.3.0-py2.py3-none-any.whl.metadata (33 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pyswarms) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pyswarms) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from pyswarms) (3.10.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from pyswarms) (25.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from pyswarms) (4.67.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from pyswarms) (1.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from pyswarms) (6.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=1.3.1->pyswarms) (1.17.0)\n",
            "Downloading pyswarms-1.3.0-py2.py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyswarms\n",
            "Successfully installed pyswarms-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rouge-score\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xoj4i7T21JNU",
        "outputId": "03a556ec-4b93-4e28-e07c-88b982d46691"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (4.67.1)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=c23b6b00539da1f426d609ce7b744dbdcccc07bdecece909cab5e67fe5ed4273\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "# Load your CSV\n",
        "df = pd.read_csv(\"preprocessed_text.csv\")\n",
        "df['Preprocessed_Text'] = df['Preprocessed_Text'].apply(ast.literal_eval)\n",
        "df['Preprocessed_Summary'] = df['Preprocessed_Summary'].apply(ast.literal_eval)\n",
        "\n",
        "# Prepare summaries\n",
        "df['Generated_Summary'] = df['Preprocessed_Text'].apply(lambda tokens: ' '.join(tokens[:5]))\n",
        "df['Reference_Summary'] = df['Preprocessed_Summary'].apply(lambda tokens: ' '.join(tokens))\n",
        "\n",
        "# Compute ROUGE-L\n",
        "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "df['ROUGE_L'] = df.apply(lambda row: scorer.score(row['Reference_Summary'], row['Generated_Summary'])['rougeL'].fmeasure, axis=1)\n",
        "\n",
        "# View results\n",
        "print(\"Average ROUGE-L:\", df['ROUGE_L'].mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzvWVe0r1KEu",
        "outputId": "d355cdf5-69aa-43ab-bf99-e44df3ec5708"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-L: 0.13528916472416472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "import numpy as np\n",
        "from rouge_score import rouge_scorer\n",
        "from pyswarms.single import GlobalBestPSO\n",
        "from functools import partial\n",
        "\n",
        "# Step 1: Load score files\n",
        "rake = pd.read_csv(\"rake_word_scores.csv\")\n",
        "textrank = pd.read_csv(\"textrank_word_scores.csv\")\n",
        "cfiof = pd.read_csv(\"cf_iof_word_scores.csv\")\n",
        "textdata = pd.read_csv(\"preprocessed_text.csv\")\n",
        "\n",
        "# Step 2: Parse dictionaries\n",
        "rake['RAKE_Word_Scores'] = rake['RAKE_Word_Scores'].apply(ast.literal_eval)\n",
        "textrank['TextRank_Word_Scores'] = textrank['TextRank_Word_Scores'].apply(ast.literal_eval)\n",
        "cfiof['CF_IOF_Word_Scores'] = cfiof['CF_IOF_Word_Scores'].apply(ast.literal_eval)\n",
        "textdata['Preprocessed_Text'] = textdata['Preprocessed_Text'].apply(ast.literal_eval)\n",
        "textdata['Preprocessed_Summary'] = textdata['Preprocessed_Summary'].apply(ast.literal_eval)\n",
        "\n",
        "# Step 3: Build ID-based dicts\n",
        "rake_dict = dict(zip(rake['Id'], rake['RAKE_Word_Scores']))\n",
        "textrank_dict = dict(zip(textrank['Id'], textrank['TextRank_Word_Scores']))\n",
        "cfiof_dict = dict(zip(cfiof['Id'], cfiof['CF_IOF_Word_Scores']))\n",
        "ref_summaries = dict(zip(textdata['Id'], textdata['Preprocessed_Summary']))\n",
        "\n",
        "# Step 4: Fitness Function (maximize ROUGE-L)\n",
        "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "\n",
        "def fitness(weights, rake_scores, textrank_scores, cfiof_scores, refs):\n",
        "    fitness_scores = []\n",
        "\n",
        "    for particle in weights:\n",
        "        w1, w2, w3 = particle\n",
        "        rouge_list = []\n",
        "\n",
        "        for idx in rake_scores.keys():\n",
        "            # Combine scores\n",
        "            combined = {}\n",
        "            words = set(rake_scores[idx]) | set(textrank_scores[idx]) | set(cfiof_scores[idx])\n",
        "            for word in words:\n",
        "                r = rake_scores[idx].get(word, 0)\n",
        "                t = textrank_scores[idx].get(word, 0)\n",
        "                c = cfiof_scores[idx].get(word, 0)\n",
        "                combined[word] = w1*r + w2*t + w3*c\n",
        "\n",
        "            top_k=len(refs[idx])\n",
        "            top_words = sorted(combined.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
        "            gen_summary = ' '.join([w for w, _ in top_words])\n",
        "            ref_summary = ' '.join(refs[idx])\n",
        "\n",
        "            rouge = scorer.score(ref_summary, gen_summary)['rougeL'].fmeasure\n",
        "            rouge_list.append(rouge)\n",
        "\n",
        "        fitness_scores.append(np.mean(rouge_list))\n",
        "\n",
        "    return -np.array(fitness_scores)  # negative for minimization\n",
        "\n",
        "# Step 5: PSO Optimization\n",
        "bounds = (np.array([0, 0, 0]), np.array([1, 1, 1]))  # Weights in [0,1]\n",
        "objective = partial(fitness, rake_scores=rake_dict, textrank_scores=textrank_dict,\n",
        "                    cfiof_scores=cfiof_dict, refs=ref_summaries)\n",
        "\n",
        "optimizer = GlobalBestPSO(n_particles=15, dimensions=3,\n",
        "                          options={'c1': 0.5, 'c2': 0.3, 'w': 0.9},\n",
        "                          bounds=bounds)\n",
        "\n",
        "best_cost, best_weights = optimizer.optimize(objective, iters=50)\n",
        "\n",
        "print(\"\\n✅ Best Weights Found:\")\n",
        "print(\"RAKE    (w₁):\", round(best_weights[0], 4))\n",
        "print(\"TextRank(w₂):\", round(best_weights[1], 4))\n",
        "print(\"CF-IOF  (w₃):\", round(best_weights[2], 4))\n",
        "print(\"Best ROUGE-L Score:\", round(-best_cost, 4))  # Reverse sign back\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W22Zwizj7usT",
        "outputId": "ea02684c-cf69-4f9c-bfbb-79f1aed582b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-12 16:46:20,533 - absl - INFO - Using default tokenizer.\n",
            "2025-06-12 16:46:20,547 - pyswarms.single.global_best - INFO - Optimize for 50 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
            "pyswarms.single.global_best: 100%|██████████|50/50, best_cost=-0.138\n",
            "2025-06-12 16:59:18,681 - pyswarms.single.global_best - INFO - Optimization finished | best cost: -0.13769616106116106, best pos: [0.25608473 0.30491818 0.01127086]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Best Weights Found:\n",
            "RAKE    (w₁): 0.2561\n",
            "TextRank(w₂): 0.3049\n",
            "CF-IOF  (w₃): 0.0113\n",
            "Best ROUGE-L Score: 0.1377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_final_feature_scores(rake_scores, textrank_scores, cfiof_scores, ref_summary_tokens,\n",
        "                             weights=(0.4, 0.3, 0.3)):\n",
        "    w1, w2, w3 = weights\n",
        "    all_tokens = set(rake_scores) | set(textrank_scores) | set(cfiof_scores)\n",
        "\n",
        "    final_scores = {}\n",
        "    for token in all_tokens:\n",
        "        r = rake_scores.get(token, 0)\n",
        "        t = textrank_scores.get(token, 0)\n",
        "        c = cfiof_scores.get(token, 0)\n",
        "        final_score = w1 * r + w2 * t + w3 * c\n",
        "        final_scores[token] = round(final_score, 4)\n",
        "\n",
        "    k = len(ref_summary_tokens)\n",
        "    top_k = sorted(final_scores.items(), key=lambda x: x[1], reverse=True)[:k]\n",
        "\n",
        "    return dict(top_k)\n",
        "\n",
        "# ✅ Generate top-k feature scores for each review\n",
        "results = []\n",
        "\n",
        "for review_id in rake_dict.keys():\n",
        "    final_scores = get_final_feature_scores(\n",
        "        rake_dict[review_id],\n",
        "        textrank_dict[review_id],\n",
        "        cfiof_dict[review_id],\n",
        "        ref_summaries[review_id],\n",
        "        weights=best_weights\n",
        "    )\n",
        "    results.append({'Id': review_id, 'Final_Scores': final_scores})\n",
        "\n",
        "# ✅ Save to CSV\n",
        "final_df = pd.DataFrame(results)\n",
        "final_df.to_csv(\"final_weighted_scores.csv\", index=False)\n",
        "\n",
        "print(\"✅ Saved final_weighted_scores.csv with top-k token scores per review.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPRl5wMeHDl0",
        "outputId": "3795a25e-58c3-4266-be6d-ba2b12abfab2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved final_weighted_scores.csv with top-k token scores per review.\n"
          ]
        }
      ]
    }
  ]
}