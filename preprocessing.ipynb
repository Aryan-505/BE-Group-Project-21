{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2157,"sourceType":"datasetVersion","datasetId":18}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-12T09:27:45.668315Z","iopub.execute_input":"2025-06-12T09:27:45.668738Z","iopub.status.idle":"2025-06-12T09:27:45.680737Z","shell.execute_reply.started":"2025-06-12T09:27:45.668705Z","shell.execute_reply":"2025-06-12T09:27:45.679683Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/amazon-fine-food-reviews/hashes.txt\n/kaggle/input/amazon-fine-food-reviews/Reviews.csv\n/kaggle/input/amazon-fine-food-reviews/database.sqlite\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"print(pd.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T09:28:02.023657Z","iopub.execute_input":"2025-06-12T09:28:02.024014Z","iopub.status.idle":"2025-06-12T09:28:02.029932Z","shell.execute_reply.started":"2025-06-12T09:28:02.023988Z","shell.execute_reply":"2025-06-12T09:28:02.028688Z"}},"outputs":[{"name":"stdout","text":"2.1.4\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"data=pd.read_csv(\"../input/amazon-fine-food-reviews/Reviews.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T08:28:59.421026Z","iopub.execute_input":"2025-06-12T08:28:59.421567Z","iopub.status.idle":"2025-06-12T08:29:04.199952Z","shell.execute_reply.started":"2025-06-12T08:28:59.421531Z","shell.execute_reply":"2025-06-12T08:29:04.198770Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T08:29:06.017665Z","iopub.execute_input":"2025-06-12T08:29:06.018072Z","iopub.status.idle":"2025-06-12T08:29:06.035389Z","shell.execute_reply.started":"2025-06-12T08:29:06.018041Z","shell.execute_reply":"2025-06-12T08:29:06.034212Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   Id   ProductId          UserId                      ProfileName  \\\n0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n\n   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n0                     1                       1      5  1303862400   \n1                     0                       0      1  1346976000   \n2                     1                       1      4  1219017600   \n3                     3                       3      2  1307923200   \n4                     0                       0      5  1350777600   \n\n                 Summary                                               Text  \n0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n2  \"Delight\" says it all  This is a confection that has been around a fe...  \n3         Cough Medicine  If you are looking for the secret ingredient i...  \n4            Great taffy  Great taffy at a great price.  There was a wid...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>ProductId</th>\n      <th>UserId</th>\n      <th>ProfileName</th>\n      <th>HelpfulnessNumerator</th>\n      <th>HelpfulnessDenominator</th>\n      <th>Score</th>\n      <th>Time</th>\n      <th>Summary</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>B001E4KFG0</td>\n      <td>A3SGXH7AUHU8GW</td>\n      <td>delmartian</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1303862400</td>\n      <td>Good Quality Dog Food</td>\n      <td>I have bought several of the Vitality canned d...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>B00813GRG4</td>\n      <td>A1D87F6ZCVE5NK</td>\n      <td>dll pa</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1346976000</td>\n      <td>Not as Advertised</td>\n      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>B000LQOCH0</td>\n      <td>ABXLMWJIXXAIN</td>\n      <td>Natalia Corres \"Natalia Corres\"</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1219017600</td>\n      <td>\"Delight\" says it all</td>\n      <td>This is a confection that has been around a fe...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>B000UA0QIQ</td>\n      <td>A395BORC6FGVXV</td>\n      <td>Karl</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1307923200</td>\n      <td>Cough Medicine</td>\n      <td>If you are looking for the secret ingredient i...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>B006K2ZZ7K</td>\n      <td>A1UQRSCLF8GW1T</td>\n      <td>Michael D. Bigham \"M. Wassir\"</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1350777600</td>\n      <td>Great taffy</td>\n      <td>Great taffy at a great price.  There was a wid...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# Drop duplicate\ndata.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"},inplace=True)#dropping duplicates\ndata.dropna(axis=0,inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T08:29:08.699725Z","iopub.execute_input":"2025-06-12T08:29:08.700073Z","iopub.status.idle":"2025-06-12T08:29:10.064296Z","shell.execute_reply.started":"2025-06-12T08:29:08.700046Z","shell.execute_reply":"2025-06-12T08:29:10.063183Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T08:29:11.695469Z","iopub.execute_input":"2025-06-12T08:29:11.695839Z","iopub.status.idle":"2025-06-12T08:29:11.838937Z","shell.execute_reply.started":"2025-06-12T08:29:11.695809Z","shell.execute_reply":"2025-06-12T08:29:11.838036Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 393914 entries, 0 to 568453\nData columns (total 10 columns):\n #   Column                  Non-Null Count   Dtype \n---  ------                  --------------   ----- \n 0   Id                      393914 non-null  int64 \n 1   ProductId               393914 non-null  object\n 2   UserId                  393914 non-null  object\n 3   ProfileName             393914 non-null  object\n 4   HelpfulnessNumerator    393914 non-null  int64 \n 5   HelpfulnessDenominator  393914 non-null  int64 \n 6   Score                   393914 non-null  int64 \n 7   Time                    393914 non-null  int64 \n 8   Summary                 393914 non-null  object\n 9   Text                    393914 non-null  object\ndtypes: int64(5), object(5)\nmemory usage: 33.1+ MB\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"example = {}\nexample['Id'] = list(data.loc[data['Id'] == 13]['Id'])\nexample['Summary'] = list(data.loc[data['Id'] == 13]['Summary'])\nexample['Text'] = list(data.loc[data['Id'] == 13]['Text'])\nprint(example)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T08:29:14.015724Z","iopub.execute_input":"2025-06-12T08:29:14.016073Z","iopub.status.idle":"2025-06-12T08:29:14.026082Z","shell.execute_reply.started":"2025-06-12T08:29:14.016048Z","shell.execute_reply":"2025-06-12T08:29:14.024933Z"}},"outputs":[{"name":"stdout","text":"{'Id': [13], 'Summary': ['My Cats Are Not Fans of the New Food'], 'Text': [\"My cats have been happily eating Felidae Platinum for more than two years. I just got a new bag and the shape of the food is different. They tried the new food when I first put it in their bowls and now the bowls sit full and the kitties will not touch the food. I've noticed similar reviews related to formula changes in the past. Unfortunately, I now need to find a new food that my cats will eat.\"]}\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import re\nimport string\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords, wordnet\nfrom nltk.tag import pos_tag\nfrom nltk.stem import WordNetLemmatizer\n\n!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T08:29:16.139632Z","iopub.execute_input":"2025-06-12T08:29:16.140002Z","iopub.status.idle":"2025-06-12T08:29:34.313709Z","shell.execute_reply.started":"2025-06-12T08:29:16.139975Z","shell.execute_reply":"2025-06-12T08:29:34.312222Z"}},"outputs":[{"name":"stdout","text":"Archive:  /usr/share/nltk_data/corpora/wordnet.zip\nreplace /usr/share/nltk_data/corpora/wordnet/lexnames? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def get_wordnet_pos(treebank_tag):\n    \"\"\"\n    return WORDNET POS compliance to WORDENT lemmatization (a,n,r,v) \n    \"\"\"\n    if treebank_tag.startswith('J'):\n        return wordnet.ADJ\n    elif treebank_tag.startswith('V'):\n        return wordnet.VERB\n    elif treebank_tag.startswith('N'):\n        return wordnet.NOUN\n    elif treebank_tag.startswith('R'):\n        return wordnet.ADV\n    else:\n        # As default pos in lemmatization is Noun\n        return wordnet.NOUN","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T08:29:37.052230Z","iopub.execute_input":"2025-06-12T08:29:37.053093Z","iopub.status.idle":"2025-06-12T08:29:37.059940Z","shell.execute_reply.started":"2025-06-12T08:29:37.053057Z","shell.execute_reply":"2025-06-12T08:29:37.058838Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"\nexample = \"<br>I ordered a pizza yesterday from @Dominos. I have to say that it was the greatest pizza I have eaten in recent times!! It was filled with cheese and delicious toppings. #CheeseIsLife</br>\"\nprint(\"Example: \", example)\n\n# Initialize resources\nstop_words = set(stopwords.words('english'))\nlemmatizer = WordNetLemmatizer()\n\ndef preprocess_text(text):\n    \"\"\"\n    Preprocesses text by performing tokenization, filtering, and lemmatization.\n    \"\"\"\n\n    text = text.lower()\n    \n    #Remove HTML Tags\n    text = re.sub(r\"<.*?>\", '', text)\n    \n    #Remove URL\n    text = re.sub(r\"https?://\\S+|www\\.\\S+\", '', text)\n    \n    #Remove mentions and hashtags\n    text = re.sub(r\"@\\w+|#\\w+\", '', text)\n    \n    text = re.sub(r\"[{}]+\".format(re.escape(string.punctuation)), ' ', text)\n    \n    \n    # Step 1: Tokenization\n    tokens = word_tokenize(text)\n    # print(\"Tokens: \", tokens)\n\n    # Step 2: Remove unnecessary tokens\n    cleaned_tokens = []\n    for token in tokens:\n        if token.isdigit():  # Remove numeric text\n            continue\n        if token in stop_words or token in string.punctuation:  # Remove stop words and punctuation\n            continue\n        cleaned_tokens.append(token)\n    # print(\"Cleaned Tokens: \", cleaned_tokens)\n\n    #POS Tagged\n    tagged_tokens = pos_tag(cleaned_tokens)\n    # print(\"Tagged Tokens: \", tagged_tokens)\n    \n    # Lemmatization and Noun Filtration\n    lemmatized_tokens = []\n    # noun_unigram = []\n    for token, tag in tagged_tokens:\n        lemma_tag = get_wordnet_pos(tag)\n        lemma = lemmatizer.lemmatize(token, lemma_tag)\n        lemmatized_tokens.append(lemma) \n      \n    \n    # print(\"Lemmatized Tokens: \", lemmatized_tokens)\n        \n    return lemmatized_tokens\n    \n\n# Example input\nprocessed_example = preprocess_text(example)\nprint(processed_example)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T10:03:02.967064Z","iopub.execute_input":"2025-06-12T10:03:02.967469Z","iopub.status.idle":"2025-06-12T10:03:02.980263Z","shell.execute_reply.started":"2025-06-12T10:03:02.967408Z","shell.execute_reply":"2025-06-12T10:03:02.979120Z"}},"outputs":[{"name":"stdout","text":"Example:  <br>I ordered a pizza yesterday from @Dominos. I have to say that it was the greatest pizza I have eaten in recent times!! It was filled with cheese and delicious toppings. #CheeseIsLife</br>\n['order', 'pizza', 'yesterday', 'say', 'great', 'pizza', 'eaten', 'recent', 'time', 'fill', 'cheese', 'delicious', 'topping']\n","output_type":"stream"}],"execution_count":70},{"cell_type":"code","source":"def get_noun_unigrams(preprocessed_tokens):\n    #POS Tagged\n    tagged_tokens = pos_tag(preprocessed_tokens)\n\n\n    noun_unigram = []\n    for token, tag in tagged_tokens:\n        if(tag[:2] == 'NN'):\n            noun_unigram.append(token)\n\n    return noun_unigram","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T10:04:55.909062Z","iopub.execute_input":"2025-06-12T10:04:55.909398Z","iopub.status.idle":"2025-06-12T10:04:55.914643Z","shell.execute_reply.started":"2025-06-12T10:04:55.909371Z","shell.execute_reply":"2025-06-12T10:04:55.913524Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"\n# Shuffle the dataset\ndata_shuffled = data.sample(frac=1, random_state=42)  # Use random_state for reproducibility\n\n# Select 1,000 random reviews\ndata_subset = data_shuffled.head(5000)\ndata_subset.head()\n\n\ndata_preprocessed = {}\ndata_preprocessed['Id'] = data_subset['Id']\ndata_preprocessed['Text'] = data_subset['Text']\ndata_preprocessed['Preprocessed_Text'] = data_subset['Text'].apply(preprocess_text)\ndata_preprocessed['Noun_Unigram'] = data_preprocessed['Preprocessed_Text'].apply(get_noun_unigrams)\n\ndata_preprocessed = pd.DataFrame(data_preprocessed)\ndata_preprocessed.head()","metadata":{"trusted":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-06-12T10:15:50.443885Z","iopub.execute_input":"2025-06-12T10:15:50.444297Z","iopub.status.idle":"2025-06-12T10:16:19.775641Z","shell.execute_reply.started":"2025-06-12T10:15:50.444265Z","shell.execute_reply":"2025-06-12T10:16:19.774647Z"}},"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"            Id                                               Text  \\\n256467  256468  I received a small jar of Bali's Best Coffee f...   \n4073      4074  I will admit, the Icicle does allow you to plu...   \n64193    64194  This house had a number of broken pieces, but ...   \n160944  160945  My wife loves using this mix for her crockpot ...   \n103614  103615  This reminds me of Fentimin's Curiosity Cola w...   \n\n                                        Preprocessed_Text  \\\n256467  [receive, small, jar, bali, best, coffee, chri...   \n4073    [admit, icicle, allow, plug, mic, xlr, jack, c...   \n64193   [house, number, broken, piece, repairable, ice...   \n160944  [wife, love, use, mix, crockpot, meal, try, ot...   \n103614  [reminds, fentimin, curiosity, cola, botanical...   \n\n                                             Noun_Unigram  \n256467  [jar, bali, coffee, christmas, store, amazon, ...  \n4073    [admit, icicle, plug, xlr, jack, computer, use...  \n64193           [house, number, piece, ice, candy, house]  \n160944  [wife, love, use, mix, crockpot, meal, try, ot...  \n103614  [reminds, curiosity, cola, undertone, coke, di...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Text</th>\n      <th>Preprocessed_Text</th>\n      <th>Noun_Unigram</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>256467</th>\n      <td>256468</td>\n      <td>I received a small jar of Bali's Best Coffee f...</td>\n      <td>[receive, small, jar, bali, best, coffee, chri...</td>\n      <td>[jar, bali, coffee, christmas, store, amazon, ...</td>\n    </tr>\n    <tr>\n      <th>4073</th>\n      <td>4074</td>\n      <td>I will admit, the Icicle does allow you to plu...</td>\n      <td>[admit, icicle, allow, plug, mic, xlr, jack, c...</td>\n      <td>[admit, icicle, plug, xlr, jack, computer, use...</td>\n    </tr>\n    <tr>\n      <th>64193</th>\n      <td>64194</td>\n      <td>This house had a number of broken pieces, but ...</td>\n      <td>[house, number, broken, piece, repairable, ice...</td>\n      <td>[house, number, piece, ice, candy, house]</td>\n    </tr>\n    <tr>\n      <th>160944</th>\n      <td>160945</td>\n      <td>My wife loves using this mix for her crockpot ...</td>\n      <td>[wife, love, use, mix, crockpot, meal, try, ot...</td>\n      <td>[wife, love, use, mix, crockpot, meal, try, ot...</td>\n    </tr>\n    <tr>\n      <th>103614</th>\n      <td>103615</td>\n      <td>This reminds me of Fentimin's Curiosity Cola w...</td>\n      <td>[reminds, fentimin, curiosity, cola, botanical...</td>\n      <td>[reminds, curiosity, cola, undertone, coke, di...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":88},{"cell_type":"markdown","source":"# Opinion Feature Extraction\n","metadata":{}},{"cell_type":"markdown","source":"## Context Similarity","metadata":{}},{"cell_type":"code","source":"!python -m spacy download en_core_web_md","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T10:05:12.358560Z","iopub.execute_input":"2025-06-12T10:05:12.358984Z","iopub.status.idle":"2025-06-12T10:05:21.965251Z","shell.execute_reply.started":"2025-06-12T10:05:12.358947Z","shell.execute_reply":"2025-06-12T10:05:21.963915Z"}},"outputs":[{"name":"stdout","text":"Collecting en-core-web-md==3.7.1\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.1/en_core_web_md-3.7.1-py3-none-any.whl (42.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.7.1) (3.7.6)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.12.5)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.66.5)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.9.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.1.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (71.0.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (24.1)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.4.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.2.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.23.4)\nRequirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2024.8.30)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (13.8.1)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.19.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (7.0.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.1.5)\nRequirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.18.0)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.16.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.2)\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_md')\n\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\n","output_type":"stream"}],"execution_count":77},{"cell_type":"code","source":"import spacy \n\nnlp = spacy.load('en_core_web_md') \n\nprint(\"Enter word\") \nword = input() \nreference_word = \"food\"\n\nnoun_token = nlp(word) \nreference_token = nlp(reference_word)\nprint(noun_token.text, noun_token.has_vector, noun_token.vector_norm) \nprint(\"Similarity:\", reference_token.similarity(noun_token)) \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T10:05:23.850718Z","iopub.execute_input":"2025-06-12T10:05:23.851086Z","iopub.status.idle":"2025-06-12T10:05:28.385939Z","shell.execute_reply.started":"2025-06-12T10:05:23.851060Z","shell.execute_reply":"2025-06-12T10:05:28.384751Z"}},"outputs":[{"name":"stdout","text":"Enter word\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" cat\n"},{"name":"stdout","text":"cat True 63.18849331586163\nSimilarity: 0.2232031355893895\n","output_type":"stream"}],"execution_count":78},{"cell_type":"code","source":"import spacy\n\nnlp = spacy.load('en_core_web_md')\n\ndef calculate_cosine_similarity(tokens, reference_word = 'food', delta = 0.4):\n    reference_token = nlp(reference_word)\n    # print(reference_token.text, reference_token.has_vector, reference_token.vector_norm) \n    \n    similar_tokens = []\n    for noun in tokens:\n        noun_token = nlp(noun)\n        # print(noun_token.text, noun_token.has_vector, noun_token.vector_norm) \n        \n        if (noun_token.has_vector):\n            similarity = reference_token.similarity(noun_token)\n            # print(f\"{noun_token} : {similarity:.4f}\")\n            if similarity > delta:\n                similar_tokens.append((noun, similarity))\n\n    return similar_tokens\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T10:07:47.495339Z","iopub.execute_input":"2025-06-12T10:07:47.495791Z","iopub.status.idle":"2025-06-12T10:07:49.440252Z","shell.execute_reply.started":"2025-06-12T10:07:47.495755Z","shell.execute_reply":"2025-06-12T10:07:49.439097Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"data_similar = {}\ndata_similar['Id'] = data_preprocessed['Id']\ndata_similar['Similar_Nouns'] = data_preprocessed['Noun_Unigram'].apply(calculate_cosine_similarity)\n\ndata_similar = pd.DataFrame(data_similar)\ndata_similar.head()","metadata":{"trusted":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-06-12T10:16:56.384474Z","iopub.execute_input":"2025-06-12T10:16:56.384834Z","iopub.status.idle":"2025-06-12T10:27:49.211754Z","shell.execute_reply.started":"2025-06-12T10:16:56.384805Z","shell.execute_reply":"2025-06-12T10:27:49.210637Z"}},"outputs":[{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"            Id                                      Similar_Nouns\n256467  256468                     [(coffee, 0.5149293216837122)]\n4073      4074                                                 []\n64193    64194                                                 []\n160944  160945  [(meal, 0.5870303326567043), (grocery, 0.55804...\n103614  103615                                                 []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Similar_Nouns</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>256467</th>\n      <td>256468</td>\n      <td>[(coffee, 0.5149293216837122)]</td>\n    </tr>\n    <tr>\n      <th>4073</th>\n      <td>4074</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>64193</th>\n      <td>64194</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>160944</th>\n      <td>160945</td>\n      <td>[(meal, 0.5870303326567043), (grocery, 0.55804...</td>\n    </tr>\n    <tr>\n      <th>103614</th>\n      <td>103615</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":89},{"cell_type":"code","source":"data_preprocessed.to_csv('preprocessed_text.csv', index = False)\ndata_similar.to_csv('similar_nouns.csv',index = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T10:32:06.059079Z","iopub.execute_input":"2025-06-12T10:32:06.059473Z","iopub.status.idle":"2025-06-12T10:32:06.265784Z","shell.execute_reply.started":"2025-06-12T10:32:06.059423Z","shell.execute_reply":"2025-06-12T10:32:06.264718Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"similar_score_example = calculate_cosine_similarity(processed_example)\nprint(similar_score_example)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T10:08:22.131275Z","iopub.execute_input":"2025-06-12T10:08:22.131670Z","iopub.status.idle":"2025-06-12T10:08:22.233957Z","shell.execute_reply.started":"2025-06-12T10:08:22.131639Z","shell.execute_reply":"2025-06-12T10:08:22.232959Z"}},"outputs":[{"name":"stdout","text":"[('pizza', 0.46639817930773697), ('pizza', 0.46639817930773697), ('cheese', 0.41129490117464185), ('delicious', 0.5739990305090508)]\n","output_type":"stream"}],"execution_count":83}]}